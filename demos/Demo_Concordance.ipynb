{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571c3c83-7e4b-47f3-a8f0-fdfffe0e8034",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Introduction**\n",
    "- ConcordanceLoader is a class that loads text data catering for CSV, Text Files, and existing DataFrames types. Once a class is created, a key word can be searched in the data and its concordance (i.e. existance) within the text is shown.\n",
    "\n",
    "- The main advantages of this class over other concordance tools are:\n",
    "    1. The ability to work with multiple data inputs (files (csv,text) and dataframes.\n",
    "    \n",
    "    2. Most concordance tools only show context of a key work limited to the line the key word is in. The context this ConcordanceLoader can work with spans more than the existing line and is limited to how the data is grouped into chunks (see below).\n",
    "    \n",
    "    3. When loading structured data that not only has text but other descriptive dimensions (for instance a csv that has a text column and other columns descibing the text), this tool can not only search for the context by keyword, but make visible the other descriptive columns associated with the matching text.\n",
    "    \n",
    "    4. Natural Language processing tools drive the keyword search. Thus the ConcordanceLoader has the potential in the future to be used in more versatile ways (for instance using languages other than english).\n",
    "    \n",
    "**How it works**\n",
    "\n",
    "- Lines of text are grouped into chunks and each row is tagged with its row number. The chunk variable is an integer reflecting the number of lines you intend to group within each chunk (i.e. the size in lines of one chunk). The context the keyword appears in is bounded by the chunk it resides in. A larger number of chunk groups the data more coarsely offering greater context (at the expense of loading times in some cases). \n",
    "\n",
    "- Text files are a special mention, where symbols can be assigned which are used search and split the text into key- value pairs. The ConcordanceLoader filters the text for these key-value pairs and converts matches it into a two columned dataframe object.\n",
    "\n",
    "\n",
    "**Limitations:**\n",
    "- If the word you are matching begins at the start of a group, the left context is limites by the start of the chunk group. A larger chunk integer is suggested.\n",
    "- Lines are tagged with a --[line_number] symbol in the text (which can be removed from the widget display). However, if the raw data has this pattern within the text it could cause confusion with line tagging method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c411e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "#from atap_widgets.concordance import ConcordanceTable, ConcordanceWidget\n",
    "from atap_widgets.concordance import ConcordanceTable, ConcordanceWidget, ConcordanceLoader\n",
    "from atap_widgets.concordance import prepare_text_df\n",
    "import dask.bag as db\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ce2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make and refer to some example data\n",
    "\n",
    "\n",
    "def basic_spacy_nlp():\n",
    "    return spacy.lang.en.English()\n",
    "\n",
    "Question_Answer_Dialogue = '../tests/data/D.QandA_Dummy.txt'\n",
    "\n",
    "MarkScottSpeach = \"../tests/data/MarkScottNationalPressClub.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b31d0",
   "metadata": {},
   "source": [
    "## ConcordanceLoader Demo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5ac4d-bbf6-474d-9118-ba01beacc7a6",
   "metadata": {},
   "source": [
    "Run the below code and explore:\n",
    "\n",
    "* Keyword searches and other options to toggle case sensitivity,regular expression and whole word matching.\n",
    "* Increasing \"Window Size(characters) \" to bring in context around the keyword.\n",
    "* Show More Multiselect dropdown can bring in more than one column by \"command + click\" when choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3733ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b584e632fddd416b81caa9c0f79be332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, description='Keyword(s):'), HBox(children=(Checkbox(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<atap_widgets.concordance.ConcordanceLoaderWidget at 0x28eed76d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CHUNK = 2\n",
    "\n",
    "#loads ConcordanceLoader class ingesting data either in csv\n",
    "DataCSV = ConcordanceLoader(type = \"csv\", path = \"../tests/data/sherlock_for_testing.csv\",chunk = CHUNK) #By Text / Csv file\n",
    "\n",
    "# or in dataframe format\n",
    "#DataCSV = ConcordanceLoader(type = \"dataframe\",df_input = sherlock_df,chunk = CHUNK)  # Or exisitng dataframe\n",
    "\n",
    "#to display widget show the class instance\n",
    "DataCSV.show() #For instance, search for \"she\" in sherlock holmes data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ac7a36-497d-4757-826e-c0b3cf7bee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>chunk</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0--To Sherlock Holmes she is always the woman.</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1--I have seldom heard him\\n    mention her un...</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2--In his eyes she eclipses and predominates t...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3--It was not that he felt any emotion akin to...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4--All emotions, and that one particularly, we...</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text speaker  chunk  row\n",
       "0     0--To Sherlock Holmes she is always the woman.       A      0    0\n",
       "1  1--I have seldom heard him\\n    mention her un...       B      0    1\n",
       "2  2--In his eyes she eclipses and predominates t...       A      1    2\n",
       "3  3--It was not that he felt any emotion akin to...       B      1    3\n",
       "4  4--All emotions, and that one particularly, we...       A      2    4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can explore how underlying data was grouped into chunks with line tags used for internal purposes\n",
    "\n",
    "DataCSV.get_grouped_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a308a67",
   "metadata": {},
   "source": [
    "## ConcordanceLoader Demo 2: Larger mutliple dimensioned (i.e. columns) text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a89032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f32e80c5e4f4c69abc3678e432de36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, description='Keyword(s):'), HBox(children=(Checkbox(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<atap_widgets.concordance.ConcordanceLoaderWidget at 0x28fd69c90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More complex and larger debate data \n",
    "CHUNK = 10 #increase chunks to expand context region. i.e. \"time\" search for instance\n",
    "data = pd.read_excel(\"../tests/data/A.debate_clean.xlsx\") #already has text_id\n",
    "DataDF = ConcordanceLoader(type = \"dataframe\",df_input = data,chunk = CHUNK)\n",
    "DataDF.show() #search \"economy\" or \"environment\" and bring in speaker from ShowMore dropdown to find out who said what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce51f13",
   "metadata": {},
   "source": [
    "## ConcordanceLoader Demo 3: Structured Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf9ac92-a6da-41e2-a468-72e75e89b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is your favourite animal in Australia?\n",
      "Name 6: Kangaroos and koalas.\n",
      "\n",
      "Question: What is your favourite animal in Australia?\n",
      "Name 1: Wombats are my favourite.\n",
      "\n",
      "Question: What is your favourite animal in Australia?\n",
      "Name 10: I don’t know, but I know I don’t like any of the poisonous spiders and dangerous snakes!\n",
      "\n",
      "Question: What is your favourite food in Australia?\n",
      "Name 10: Tomatos for sure!\n",
      "\n",
      "Question: What is your favourite food in Australia?\n",
      "Name 6: I decline to answer that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is what data looks like. Notice the key:value structure within the text.\n",
    "! head -15 $Question_Answer_Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b33d8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.core.strings' has no attribute 'StringMethods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m symbol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      5\u001b[0m CHUNK \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 7\u001b[0m DataDF \u001b[38;5;241m=\u001b[39m \u001b[43mConcordanceLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtxt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuestion_Answer_Dialogue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mre_symbol_txt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m DataDF\u001b[38;5;241m.\u001b[39mshow() \u001b[38;5;66;03m#search tomatos, pick \"key\" in \"Show More\" to bring in key associated with text.\u001b[39;00m\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/atap_widgets/concordance.py:181\u001b[0m, in \u001b[0;36mConcordanceLoader.__init__\u001b[0;34m(self, path, type, df_input, re_symbol_txt, chunk)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_input \u001b[38;5;241m=\u001b[39m df_input\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mre_symbol_txt \u001b[38;5;241m=\u001b[39m re_symbol_txt\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_data_if_chunking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouped_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[1;32m    184\u001b[0m )  \u001b[38;5;66;03m# Interates over chunks to create a column for grouping\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mungrouped_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouped_data\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/atap_widgets/concordance.py:210\u001b[0m, in \u001b[0;36mConcordanceLoader.read_data_if_chunking\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_a_dataframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_input)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 210\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_a_dataframe(df)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/atap_widgets/concordance.py:240\u001b[0m, in \u001b[0;36mConcordanceLoader.read_txt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(record):\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    236\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m: record[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: record[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    238\u001b[0m         }\n\u001b[0;32m--> 240\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# just read without splitting and assume its all just text - no column structure\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     b \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    243\u001b[0m         db\u001b[38;5;241m.\u001b[39mread_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_location)\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m r: \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    246\u001b[0m     )\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/core.py:1594\u001b[0m, in \u001b[0;36mBag.to_dataframe\u001b[0;34m(self, meta, columns, optimize_graph)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create Dask Dataframe from a Dask Bag.\u001b[39;00m\n\u001b[1;32m   1546\u001b[0m \n\u001b[1;32m   1547\u001b[0m \u001b[38;5;124;03mBag should contain tuples, dict records, or scalars.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;124;03m0  Charlie      300\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m-> 1594\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1597\u001b[0m     head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pyarrow_compat\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch, rolling\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     DataFrame,\n\u001b[1;32m      7\u001b[0m     Index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     to_timedelta,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aggregation\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/backends.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpercentile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _percentile\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CreationDispatch, DaskBackendEntrypoint\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame, Index, Scalar, Series, _Frame\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     categorical_dtype_dispatch,\n\u001b[1;32m     25\u001b[0m     concat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     union_categoricals_dispatch,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_array_nonempty, make_scalar\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/core.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblockwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blockwise, BlockwiseDep, BlockwiseDepDict, blockwise\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m globalmethod\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m methods\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     PANDAS_GT_140,\n\u001b[1;32m     38\u001b[0m     PANDAS_GT_150,\n\u001b[1;32m     39\u001b[0m     check_numeric_only_deprecation,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CachedAccessor, DatetimeAccessor, StringAccessor\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/methods.py:22\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#  preserve compatibility while moving dispatch objects\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     concat,\n\u001b[1;32m     13\u001b[0m     concat_dispatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     union_categoricals,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_dataframe_like, is_index_like, is_series_like\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# cuDF may try to import old dispatch functions\u001b[39;00m\n\u001b[1;32m     25\u001b[0m hash_df \u001b[38;5;241m=\u001b[39m hash_object_dispatch\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/utils.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_scheduler, is_dask_collection\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_deps\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 register pandas extension types\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     _dtypes,\n\u001b[1;32m     21\u001b[0m     methods,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GT_110, PANDAS_GT_120, tm  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa : F401\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     make_meta,\n\u001b[1;32m     26\u001b[0m     make_meta_obj,\n\u001b[1;32m     27\u001b[0m     meta_nonempty,\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/_dtypes.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GT_150\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_array_nonempty, make_scalar\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@make_array_nonempty\u001b[39m\u001b[38;5;241m.\u001b[39mregister(pd\u001b[38;5;241m.\u001b[39mDatetimeTZDtype)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(dtype):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39marray([pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;241m1\u001b[39m), pd\u001b[38;5;241m.\u001b[39mNaT], dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/extensions.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSupport for pandas ExtensionArray in dask.dataframe.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mSee :ref:`extensionarrays` for more.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     register_dataframe_accessor,\n\u001b[1;32m      8\u001b[0m     register_index_accessor,\n\u001b[1;32m      9\u001b[0m     register_series_accessor,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dispatch\n\u001b[1;32m     13\u001b[0m make_array_nonempty \u001b[38;5;241m=\u001b[39m Dispatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_array_nonempty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/accessor.py:190\u001b[0m\n\u001b[1;32m    129\u001b[0m     _accessor_methods \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masfreq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceil\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtz_localize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    148\u001b[0m     _accessor_properties \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    187\u001b[0m     )\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStringAccessor\u001b[39;00m(Accessor):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Accessor object for string properties of the Series values.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    >>> s.str.lower()  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/dataframe/accessor.py:276\u001b[0m, in \u001b[0;36mStringAccessor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m         meta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_series\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_map(method, pat\u001b[38;5;241m=\u001b[39mpat, n\u001b[38;5;241m=\u001b[39mn, expand\u001b[38;5;241m=\u001b[39mexpand, meta\u001b[38;5;241m=\u001b[39mmeta)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;129m@derived_from\u001b[39m(\n\u001b[0;32m--> 276\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringMethods\u001b[49m,\n\u001b[1;32m    277\u001b[0m     inconsistencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``expand=True`` with unknown ``n`` will raise a ``NotImplementedError``\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, pat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Known inconsistencies: ``expand=True`` with unknown ``n`` will raise a ``NotImplementedError``.\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, pat\u001b[38;5;241m=\u001b[39mpat, n\u001b[38;5;241m=\u001b[39mn, expand\u001b[38;5;241m=\u001b[39mexpand)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.core.strings' has no attribute 'StringMethods'"
     ]
    }
   ],
   "source": [
    "# With text types, you can define a symbol to split lines assuming all relevant info is in the structure key [SYMBOL] value.\n",
    "# The keyword is searched in the value field, and the additional key column (whateve was before the SYMBOL) can be selected\n",
    "symbol = r':' \n",
    "\n",
    "CHUNK = 4\n",
    "\n",
    "DataDF = ConcordanceLoader(type = \"txt\",path = Question_Answer_Dialogue,re_symbol_txt = symbol,chunk = CHUNK)\n",
    "\n",
    "DataDF.show() #search tomatos, pick \"key\" in \"Show More\" to bring in key associated with text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58130ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Name 1', 'Name 10', 'Name 6', 'Name11', 'Question'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a side note, one can work with underlying dataframe for further analysis.\n",
    "DataDF.get_grouped_data().sort_values('key').key.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7631b",
   "metadata": {},
   "source": [
    "## ConcordanceLoader Demo 4: Plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6197e76-4ec5-4785-a332-aff2eedbb9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I acknowledge that we meet today on the ancestral lands of the Ngunnawal people, the traditional custodians of this land. I pay my respects to elders past and present, and those who have cared for and continue to care for country.\n",
      "\n",
      "It’s great to be with you.\n",
      "\n",
      "The University of Sydney is Australia’s oldest university. We took in our first students in 1852 and just yesterday released our aspirations for the decade through to 2032, by which time we’ll be closing in on the end of the University’s second century.\n",
      "\n",
      "In considering our future, we humbly acknowledge that for hundreds of centuries before the University of Sydney opened its doors, generations of First Nations peoples have been exchanging knowledge on the ancestral lands on which the University’s campuses and facilities now stand. And as we create a university for the future, we aim to extend and build upon this prior knowledge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the underlying data communicates the University of Sydney 2022 Strategy\n",
    "! head -n 10 $MarkScottSpeach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80adaaa9-0ff0-4b84-b5ca-86d87038861d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc6dbfcf0fe495dbeb2d165e0ac5836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Keyword(s):'), HBox(children=(Checkbox(value=False, description='En…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<atap_widgets.concordance.ConcordanceLoaderWidget at 0x29e21c190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads text without any key value structure \n",
    "CHUNK = 4\n",
    "DataDF = ConcordanceLoader(type = \"txt\",path = MarkScottSpeach)\n",
    "DataDF.show() #search for \"pandemic\" for instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409d63b-e1c3-4635-9e3a-2e55ad66eb8e",
   "metadata": {},
   "source": [
    "### Simpler functionality is still present that that reflects older DataWidget and Concordance Table development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60c2e28c-0f3f-423c-b87a-6d7dbb4b2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hcro4489/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/atap_widgets/concordance.py:607: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  ].apply(pd.Series)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4490aea547d3424da5313bcf3831f223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', continuous_update=False, description='Keyword(s):'), HBox(children=(Checkbox(val…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original_data = DataCSV.get_original_data()\n",
    "\n",
    "original_data.head() #chuch and row columns added to original data.\n",
    "\n",
    "data = pd.read_csv(\"../tests/data/sherlock_for_testing.csv\")                  \n",
    "data =  prepare_text_df(data)\n",
    "\n",
    "table = ConcordanceTable(df = data,keyword = \"she\")\n",
    "table\n",
    "\n",
    "search_results_df = table.to_dataframe() #extract results into dataframe\n",
    "search_results_df.head()\n",
    "\n",
    "oldWidget = ConcordanceWidget(data) #run simplier widget (no chunks or context)\n",
    "oldWidget.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2a772-c81e-4133-93ef-6f1377c177fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
