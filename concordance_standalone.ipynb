{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e007218f163f61",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ATAP Concordancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad19ba24ac2609",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aec810dd29aeb8d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This notebook is a Concordancer tool which allows users to upload text data (eg. .csv or .txt file) and to search the text for each instance of a search term, presenting it in the form of a concordance. The Concordancer retrieves all relevant instances of the search term and displays them for users in the tool as well as making them available for download as a CSV file for additional analysis. It has specifically been designed to allow users (i) to undertake ‘dialogic’ analysis (when the input consists of related text pairs, such as question-answer or social media post-response) and/or (ii) to make visible the meta-data that are associated with the occurrence of the search term (when available in the input; for example, speaker identity, political affiliation, company, etc).\n",
    "\n",
    "To do so, the data that is loaded into the notebook must contain ‘structured’ data, where one column consists of ‘text’ (eg the question or social media post) and the other columns consist of either the associated text of the dialogic pair (eg the relevant answer or the relevant reply/comment) or of metadata (describing aspects of the text). This is explained further below. In addition to this analysis of structured data, the notebook can create its own structured data based on symbols present in the uploaded text(s), automatically splitting the data preceding and following the relevant symbol (e.g. a colon or a question mark). This is also explained and illustrated further below.\n",
    "\n",
    "In sum, this notebook is not meant to feature all types of analyses offered by current off-the-shelf Concordancers and should be considered as complementary to such existing tools. You may want to use this tool if you are interested in using a Concordancer for dialogic analysis or exploring the relationship between search term and meta-data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18552f3af4f3ee4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## File upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb849a2ac775bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Upload a single txt or CSV file. Only one file can be uploaded and analysed at a time. Note that there is no progress indicator, but you will get a message if you run the next cell prior to the uploading process having completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f02ffb5780d76b7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd31e4397334c1b8726e25289675ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv,.txt', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from src.atap_widgets.concordance import ConcordanceLoader\n",
    "uploader = FileUpload(accept=\".csv,.txt\")\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c6567-7f65-43d3-a3a5-4109255fefeb",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c22a8d-9d74-47c8-918d-2e7781b6186e",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "1. Upload a file by clicking the above 'Upload' button\n",
    "2. Run the code block below and wait for the concordancer tool to display\n",
    "\n",
    "Note: if you want to analyse dialogic structures (question-answer; post-response) or if you want to analyse metadata associated with your search term (such as the identity of the speaker, the date, etc.), you should upload your text data as a ‘structured’ .csv file. Note that you can save an .xlsx spreadsheet as .csv file within Excel (‘Save as’). Make sure that the text you want to analyse is included in the column titled ‘text’. A mocked-up example is provided below.\n",
    "\n",
    "![Structured text](./concordance_standalone_imgs/structured_eg.png)\n",
    "\n",
    "### Search\n",
    "1. Enter a search term into the search field and press enter on your keyboard to perform a search\n",
    "2. Toggle the checkboxes below the search field to enable/disable regular expression matching, case sensitivity, and whole word matching\n",
    "\n",
    "Note that without regular expressions the search field uses exact matching and considers punctuation (for example, a search for “oh my god” will NOT retrieve instances of “oh, my god”).\n",
    "\n",
    "Regular expressions can be used for advanced searches. Here are some examples:\n",
    "- `\\b(find\\w*|.*ness)\\b` - matches strings that start with 'find' or end in 'ness'\n",
    "- `oh,? my god` - matches \"oh my god\" or \"oh, my god\"\n",
    "- `\\bhope\\w{2}\\b` - matches strings that start with \"hope\" followed by 2 characters\n",
    "- `\\bwomen(?:\\s\\w+)?\\smen\\b` - matches strings that start with \"women\" and end in \"men\" with 0 or 1 words between them, e.g. \"women and men\", \"women or men\" will both match\n",
    "- `\\bthe\\s\\w+\\sof\\b` - matches strings that start with \"the\" and end in \"of\" with exactly 1 word between them, e.g. \"the minister of\" will match but \"the of\" will not\n",
    "- `\\b(his|him|himself)\\b` - matches any of the following words: \"him\", \"his\", \"himself\"\n",
    "- `\\b\\d+\\s[A-Za-z]+\\b` - matches strings that begin with a number and end with a word, e.g. \"10 dogs\" will match\n",
    "\n",
    "### Display\n",
    "1. Use the 'Sort by' dropdown to sort by text_id, left context, or right context\n",
    "    - The text_id field corresponds to the line number of the match in the text (where text_id is 0 for the first line). Sorting by text_id will display results in the order which they appear in the text.\n",
    "    - If sorting by left or right context, sorting is done in alphabetical order.\n",
    "2. If your data contains metadata columns, use the 'Show More' field to select a metadata column to display.\n",
    "    - to select multiple metadata columns, hold the control/command key and click multiple\n",
    "3. Export the file to an Excel spreadsheet by providing an appropriate file name and clicking the button labelled \"Export to Excel\".\n",
    "   This sheet will appear in the Jupyter file window on the left and can be downloaded by right-clicking the file and clicking \"Download\"\n",
    "\n",
    "- If the context windows don't display all the text you would like to display, change the window size using the \"Window size\" field\n",
    "- If there are many results from the search, navigate through the pages of results using the 'Page' navigator field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6333f-f6a5-4222-9361-785990cc8ae8",
   "metadata": {},
   "source": [
    "## Concordancer\n",
    "Ensure you have uploaded a file and then run the code cell below to show the Concordancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1897bd6ccdd924",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 7279: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(uploaded_file\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m      8\u001b[0m     file_type \u001b[38;5;241m=\u001b[39m uploaded_file\u001b[38;5;241m.\u001b[39mname[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m---> 10\u001b[0m     concordance_loader \u001b[38;5;241m=\u001b[39m \u001b[43mConcordanceLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     concordance_loader\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/src/atap_widgets/concordance.py:181\u001b[0m, in \u001b[0;36mConcordanceLoader.__init__\u001b[0;34m(self, path, type, df_input, re_symbol_txt, chunk)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_input \u001b[38;5;241m=\u001b[39m df_input\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mre_symbol_txt \u001b[38;5;241m=\u001b[39m re_symbol_txt\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_data_if_chunking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouped_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[1;32m    184\u001b[0m )  \u001b[38;5;66;03m# Interates over chunks to create a column for grouping\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mungrouped_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouped_data\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/src/atap_widgets/concordance.py:210\u001b[0m, in \u001b[0;36mConcordanceLoader.read_data_if_chunking\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_a_dataframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_input)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 210\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_a_dataframe(df)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/src/atap_widgets/concordance.py:247\u001b[0m, in \u001b[0;36mConcordanceLoader.read_txt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# just read without splitting and assume its all just text - no column structure\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     b \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    243\u001b[0m         db\u001b[38;5;241m.\u001b[39mread_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_location)\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m r: \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 247\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[0;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/core.py:2574\u001b[0m, in \u001b[0;36mto_dataframe\u001b[0;34m(seq, columns, dtypes)\u001b[0m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(seq, columns, dtypes):\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m-> 2574\u001b[0m     seq \u001b[38;5;241m=\u001b[39m \u001b[43mreify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2575\u001b[0m     \u001b[38;5;66;03m# pd.DataFrame expects lists, only copy if necessary\u001b[39;00m\n\u001b[1;32m   2576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/core.py:1854\u001b[0m, in \u001b[0;36mreify\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreify\u001b[39m(seq):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, Iterator):\n\u001b[0;32m-> 1854\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq[\u001b[38;5;241m0\u001b[39m], Iterator):\n\u001b[1;32m   1856\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, seq))\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/core.py:2033\u001b[0m, in \u001b[0;36m_MapChunk.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2032\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2033\u001b[0m         vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters]\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_all_iterators_consumed()\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/core.py:2033\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2032\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2033\u001b[0m         vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters]\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_all_iterators_consumed()\n",
      "File \u001b[0;32m~/My Drive/USYD SIH/Repos/atap_widgets/venv/lib/python3.10/site-packages/dask/bag/text.py:175\u001b[0m, in \u001b[0;36mfile_to_blocks\u001b[0;34m(include_path, lazy_file, delimiter)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[1;32m    171\u001b[0m         (line, lazy_file\u001b[38;5;241m.\u001b[39mpath) \u001b[38;5;28;01mif\u001b[39;00m include_path \u001b[38;5;28;01melse\u001b[39;00m line\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m [line \u001b[38;5;241m+\u001b[39m delimiter \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parts[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (line, lazy_file\u001b[38;5;241m.\u001b[39mpath) \u001b[38;5;28;01mif\u001b[39;00m include_path \u001b[38;5;28;01melse\u001b[39;00m line\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 7279: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "uploaded = len(uploader.value) > 0\n",
    "if uploaded:\n",
    "    uploaded_file = uploader.value[0]\n",
    "    file_name = uploaded_file.name\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        fp.write(uploaded_file.content)\n",
    "    \n",
    "    file_type = uploaded_file.name[-3:]\n",
    "    \n",
    "    concordance_loader = ConcordanceLoader(path=file_name, type=file_type)\n",
    "    concordance_loader.show()\n",
    "else:\n",
    "    print(\"Ensure you upload a file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786e4bf-577d-4041-b0b8-ec6a32fcab2b",
   "metadata": {},
   "source": [
    "## Concordancer - Unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fd7c7-2c91-47fe-8404-8b0a842c0e78",
   "metadata": {},
   "source": [
    "The dialogic feature is a more advanced feature of the concordancer and allows you to analyse discourse structures in unstructured text (text that does not contain different columns with aligned text pairs or aligned text-metadata pairs). It requires that your text contains a symbol that is consistently used to identify a structure. For instance, your text might use the colon symbol (:) ONLY after speakers and before their respective dialogue, as in the example below. \n",
    "\n",
    "![Dialogue example 1](./concordance_standalone_imgs/dialogue_eg1.png)\n",
    "\n",
    "Or your text might use the question mark symbol (?) only after the interviewer’s question, as in the example below:\n",
    "\n",
    "![Dialogue example 2](./concordance_standalone_imgs/dialogue_eg2.png)\n",
    "\n",
    "If your text uses such symbols consistently, this would allow you to use this tool to structure your text, for example into speaker-text pairs or question-answer pairs, and analyse it accordingly (similar to structured data).\n",
    "\n",
    "To do so, you specify a character across which the text data will be split. For example, if your text is of the format speaker: spoken words, you can specify the \"splitter\" to be :, which will create a column called \"key\" for the speaker and a column for the spoken words. You can then see which speaker spoke the words in a given concordance line. Note that information on the left of the chosen symbol (here speaker) will be a metadata column, while information on the right of the chosen symbol (here the words spoken by the speaker) will be treated as the text that is searched for with the Concordancer.\n",
    "\n",
    "In the code cell below, replace the : between the quotation marks to specify a different splitter character (for example a question mark), depending on what symbols are present in the uploaded text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece7014-669d-4226-b1cb-a4046ce7dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = \":\"\n",
    "\n",
    "uploaded = len(uploader.value) > 0\n",
    "if uploaded:\n",
    "    uploaded_file = uploader.value[0]\n",
    "    file_name = uploaded_file.name\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        fp.write(uploaded_file.content)\n",
    "    \n",
    "    file_type = uploaded_file.name[-3:]\n",
    "    \n",
    "    concordance_loader = ConcordanceLoader(path=file_name, type=file_type, re_symbol_txt=splitter)\n",
    "    concordance_loader.show()\n",
    "else:\n",
    "    print(\"Ensure you upload a file!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
